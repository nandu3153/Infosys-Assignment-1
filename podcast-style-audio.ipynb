{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ***Audio Analysis – Preprocessing Assignment***\n",
        "**Submitted by: M. Narayan Naidu**\n",
        "\n",
        "**Date: 4th December 2025**\n",
        "\n",
        "Goal: Clean podcast-style audio → 16kHz mono speech (ready for transcription)\n",
        "\n",
        "Steps we will do:\n",
        "1. Load audio files\n",
        "2. Resample to 16kHz\n",
        "3. Convert stereo → mono\n",
        "4. Normalize volume\n",
        "5. Reduce background noise\n",
        "6. Remove silence from start/end\n",
        "7. Keep only speaking parts using VAD\n"
      ],
      "metadata": {
        "id": "ddw7Do8VBXB5"
      }
    },
    {
      "cell_type": "markdown",
      "source": ["## 1. Install & Import (run once)"]
      "metadata": {
        "id": "CTNWYKUT7EdB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q mlcroissant librosa soundfile noisereduce webrtcvad tqdm matplotlib\n",
        "!apt-get -qq install -y ffmpeg\n",
        "\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "import numpy as np\n",
        "import noisereduce as nr\n",
        "import webrtcvad\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import mlcroissant as mlc\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "TARGET_SR = 16000  # 16kHz – perfect for speech models"
      ],
      "metadata": {
        "id": "P4mqAUiA6ec2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": ["## 2. Download LJSpeech Dataset (or upload your own)"]
      "metadata": {
        "id": "BZM8kT8X7LRL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ZsnCZFqKBCvs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZmTPZ9PX5mdM"
      },
      "outputs": [],
      "source": [
        "# Folder setup\n",
        "WORK_DIR = Path(\"/content/audio_project\")\n",
        "RAW_DIR = WORK_DIR / \"raw\"\n",
        "PROCESSED_DIR = WORK_DIR / \"processed\"\n",
        "PROCESSED_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Download dataset automatically\n",
        "print(\"Downloading LJSpeech dataset...\")\n",
        "ds = mlc.Dataset(\"https://huggingface.co/datasets/lj_speech/resolve/main/croissant/metadata.json\")\n",
        "records = list(ds.records(record_set=\"lj_speech\"))\n",
        "df = pd.DataFrame(records)\n",
        "print(f\"Found {len(df)} audio files!\")\n",
        "df.head()"
      ],
    },
    {
      "cell_type": "markdown",
      "source": ["## 3. Our 7 Simple Functions (same as before, just cleaner)"]
      "metadata": {
        "id": "-KU1SHi_-eRO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_audio(path):\n",
        "    y, sr = sf.read(path)\n",
        "    y = y.astype(np.float32)\n",
        "    return y, sr\n",
        "\n",
        "def resample_audio(y, orig_sr):\n",
        "    if orig_sr != TARGET_SR:\n",
        "        y = librosa.resample(y, orig_sr=orig_sr, target_sr=TARGET_SR)\n",
        "    return y\n",
        "\n",
        "def to_mono(y):\n",
        "    if y.ndim > 1:\n",
        "        y = np.mean(y, axis=1)\n",
        "    return y\n",
        "\n",
        "def normalize_audio(y):\n",
        "    max_val = np.max(np.abs(y))\n",
        "    if max_val > 0:\n",
        "        y = y / max_val  # simple peak normalization\n",
        "    return y\n",
        "\n",
        "def denoise_audio(y):\n",
        "    return nr.reduce_noise(y=y, sr=TARGET_SR)\n",
        "\n",
        "def trim_silence(y):\n",
        "    y_trimmed, _ = librosa.effects.trim(y, top_db=20)\n",
        "    return y_trimmed\n",
        "\n",
        "def apply_vad(y):\n",
        "    vad = webrtcvad.Vad(3)  # 3 = quite strict, good for clean speech\n",
        "    frame_duration = 0.03  # 30 ms\n",
        "    frame_samples = int(TARGET_SR * frame_duration)\n",
        "    \n",
        "    # Convert to int16 (required by webrtcvad)\n",
        "    audio_int16 = (y * 32767).astype(np.int16)\n",
        "    voiced_parts = []\n",
        "    \n",
        "    for i in range(0, len(audio_int16), frame_samples):\n",
        "        frame = audio_int16[i:i+frame_samples]\n",
        "        if len(frame) < frame_samples:\n",
        "            break\n",
        "        if vad.is_speech(frame.tobytes(), TARGET_SR):\n",
        "            voiced_parts.append(frame)\n",
        "    \n",
        "    if not voiced_parts:\n",
        "        return y  # if nothing detected, return original\n",
        "    \n",
        "    voiced = np.concatenate(voiced_parts)\n",
        "    return voiced.astype(np.float32) / 32767.0"
      ],
      "metadata": {
        "id": "ePuWBqT--fTm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: load"
      ],
      "metadata": {
        "id": "sNpufB-R-_bv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def load_audio(path):\n",
        "    y, sr = sf.read(path)\n",
        "    # ensure float32\n",
        "    if y.dtype != np.float32:\n",
        "        y = y.astype(np.float32)\n",
        "    return y, sr"
      ],
      "metadata": {
        "id": "aFAgxSZdAXtj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": ["## 4. Process All Files (with progress bar)"],
      "metadata": {
        "id": "ajvN-g4iAfy3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing\"):\n",
        "    input_path = Path(row[\"audio\"][\"path\"])  # Croissant gives full path\n",
        "    if not input_path.exists():\n",
        "        continue\n",
        "    \n",
        "    y, sr = load_audio(input_path)\n",
        "    \n",
        "    y = resample_audio(y, sr)\n",
        "    y = to_mono(y)\n",
        "    y = normalize_audio(y)\n",
        "    y = denoise_audio(y)\n",
        "    y = trim_silence(y)\n",
        "    y = apply_vad(y)\n",
        "    \n",
        "    # Save clean file\n",
        "    output_path = PROCESSED_DIR / f\"clean_{idx:05d}.wav\"\n",
        "    sf.write(output_path, y, TARGET_SR)\n",
        "\n",
        "print(\"\\nAll done! Clean files saved in:\", PROCESSED_DIR)"
      ],
      "metadata": {
        "id": "7C3zMER_AdFD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": ["## 5. Listen & See One Example (optional but cool)"],
      "metadata": {
        "id": "mfvZgr1_AkGc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pick any clean file\n",
        "example_file = sorted(PROCESSED_DIR.glob(\"*.wav\"))[10]\n",
        "y_clean, _ = librosa.load(example_file, sr=TARGET_SR)\n",
        "\n",
        "plt.figure(figsize=(12,4))\n",
        "librosa.display.waveshow(y_clean, sr=TARGET_SR)\n",
        "plt.title(\"Cleaned Audio - Ready for Transcription!\")\n",
        "plt.xlabel(\"Time (s)\")\n",
        "plt.ylabel(\"Amplitude\")\n",
        "plt.show()\n",
        "\n",
        "# Play it (Colab only)\n",
        "import IPython.display as ipd\n",
        "ipd.Audio(example_file)"
      ],
      "metadata": {
        "id": "pwjg1IvxAkQ9"
      },
      "execution_count": null,
      "outputs": []
    }
}
